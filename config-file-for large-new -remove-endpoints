import os
import torch  # Add this at the top of config.py if missing

from typing import Dict, List

class Config:
    # Model configurations
    WHISPER_MODEL = "openai/whisper-large-v3"
    INDIC_MODEL = "ai4bharat/indic-conformer-600m-multilingual"
    
    # Smart path detection for offline model loading
    if os.path.exists("/app/models"):  # Docker environment
        MODEL_CACHE_DIR = "/app/models"
    else:  # Local development
        MODEL_CACHE_DIR = os.path.join(os.path.dirname(__file__), "..", "models")
    
    USE_OFFLINE_MODELS = True  # Force offline mode for both Docker and local

    # Audio processing
    SAMPLE_RATE = 16000
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    
    # Supported formats
    SUPPORTED_FORMATS = {'.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac', '.wma'}
    
    # Multi-audio detection settings
    MIN_SILENCE_DURATION = 500  # milliseconds
    SILENCE_THRESHOLD = -40     # dBFS (decibels relative to full scale)
    KEEP_SILENCE_PADDING = 100  # milliseconds
    MIN_SEGMENT_DURATION = 1000 # milliseconds (minimum segment length to process)
    
    # Complete Indic language mappings (22 official Indian languages)
    WHISPER_TO_INDIC_MAPPING = {
        # Indo-European Family
        'hi': 'hi', 'bn': 'bn', 'pa': 'pa', 'gu': 'gu', 'mr': 'mr',
        'or': 'or', 'as': 'as', 'ur': 'ur', 'ne': 'ne', 'ks': 'ks',
        'sd': 'sd', 'sa': 'sa', 'mai': 'mai', 'doi': 'doi', 'kok': 'kok',
        # Dravidian Family
        'ta': 'ta', 'te': 'te', 'kn': 'kn', 'ml': 'ml',
        # Sino-Tibetan Family
        'mni': 'mni', 'brx': 'brx',
        # Austro-Asiatic Family
        'sit': 'sit',
    }
    
    # Device configuration
    USE_GPU = os.getenv("USE_GPU", "false").lower() == "true"  # Default to false for Docker CPU
    
    @classmethod
    def get_device(cls):
        import torch
        if cls.USE_GPU and torch.cuda.is_available():
            return "cuda"
        return "cpu"
    
    @classmethod
    def get_gpu_info(cls):
        import torch
        if torch.cuda.is_available():
            return {
                "gpu_count": torch.cuda.device_count(),
                "current_device": torch.cuda.current_device(),
                "device_name": torch.cuda.get_device_name(),
                "memory_allocated": torch.cuda.memory_allocated(),
                "memory_reserved": torch.cuda.memory_reserved()
            }
        return {"gpu_available": False}
    
    @classmethod
    def get_model_kwargs(cls):
        """Return model loading kwargs for offline usage"""
        return {
            'cache_dir': cls.MODEL_CACHE_DIR,
            'local_files_only': cls.USE_OFFLINE_MODELS,
            'resume_download': False,
            'torch_dtype': torch.float32  # Fix tensor type mismatch
        }
